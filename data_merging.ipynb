{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_2016 = pd.read_csv('CDS_2016_va.csv')\n",
    "data_2017 = pd.read_csv('CDS_2017_va.csv')\n",
    "data_2018 = pd.read_csv('CDS_2018_va.csv')\n",
    "data_2019 = pd.read_csv('CDS_2019_NO_LABEL.csv')\n",
    "asignaturas = pd.read_csv('Asignaturas.csv', sep = ';')\n",
    "clientes = pd.read_csv('Clientes.csv', sep = ';')\n",
    "cursos = pd.read_csv('Cursos.csv', sep = ';')\n",
    "lengua = pd.read_csv('Lengua.csv', sep = ';')\n",
    "tme = pd.read_csv('TME.csv', sep = ';')\n",
    "ts = pd.read_csv('TS.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entries in column 'Curso' starts with a 'c' for data_2018\n",
    "data_2018['Curso'] =  data_2018.Curso.str[1:].astype(int).copy()\n",
    "\n",
    "# entries in column 'Año natural' are 18 instead of 2018\n",
    "data_2018['Año natural'] = 2018\n",
    "\n",
    "# some column labels for data_2016 are different\n",
    "data_2016.columns = data_2017.columns\n",
    "\n",
    "# data_2017 has duplicate rows\n",
    "data_2017.drop_duplicates(subset = None, keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Asignatura ###\n",
    "\n",
    "# remove non-numerical values from the asignatura code\n",
    "asignaturas = asignaturas.loc[~asignaturas.Asignatura.isin(['EE01', '#']),:].copy()\n",
    "\n",
    "# convert the asignatura code the integer\n",
    "asignaturas['Asignatura'] = asignaturas.Asignatura.astype(int).copy()\n",
    "\n",
    "### Curso ###\n",
    "\n",
    "# remove non-numerical values from the curso code\n",
    "cursos = cursos.loc[~cursos.Curso.isin(['#']),:].copy()\n",
    "\n",
    "# convert the curso code the integer\n",
    "cursos['Curso'] = cursos.Curso.astype(int).copy()\n",
    "\n",
    "# keep only relevant columns\n",
    "cursos = cursos[['Curso', 'N_Curso']].copy()\n",
    "\n",
    "### TME ###\n",
    "\n",
    "# remove non-numerical values from the curso code\n",
    "tme = tme.loc[~tme['Tipo Material Educat'].isin(['#']),:].copy()\n",
    "\n",
    "# convert the curso code the integer\n",
    "tme['Tipo Material Educativo'] = tme['Tipo Material Educat'].astype(int).copy()\n",
    "\n",
    "# drop original column\n",
    "tme.drop('Tipo Material Educat', axis = 1, inplace = True)\n",
    "\n",
    "### TS ###\n",
    "\n",
    "# remove non-numerical values from the curso code\n",
    "ts = ts.loc[~ts['Tipo Soporte Actual'].isin(['#']),:].copy()\n",
    "\n",
    "# convert the curso code the integer\n",
    "ts['Tipo Soporte Actual'] = ts['Tipo Soporte Actual'].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with all datasets\n",
    "datasets = [data_2016, data_2017, data_2018, data_2019]\n",
    "\n",
    "# loop over this list\n",
    "for i, data in enumerate(datasets):\n",
    "    \n",
    "    # join data\n",
    "    datasets[i] = datasets[i].merge(asignaturas, how = 'left', on = 'Asignatura')\n",
    "    datasets[i] = datasets[i].merge(clientes, how = 'left', on = 'Id_Cliente')\n",
    "    datasets[i] = datasets[i].merge(cursos, how = 'left', on = 'Curso')\n",
    "    datasets[i] = datasets[i].merge(lengua, how = 'left', on = 'Lengua')\n",
    "    datasets[i] = datasets[i].merge(tme, how = 'left', on = 'Tipo Material Educativo')\n",
    "    datasets[i] = datasets[i].merge(ts, how = 'left', on = 'Tipo Soporte Actual')\n",
    "    \n",
    "    # create a unique record id\n",
    "    datasets[i]['record_id'] = list(map(lambda a, b, c, d, e, f: str(a) + '_' + \\\n",
    "                                                                 str(b) + '_' + \\\n",
    "                                                                 str(c) + '_' + \\\n",
    "                                                                 str(d) + '_' + \\\n",
    "                                                                 str(e) + '_' + \\\n",
    "                                                                 str(f),\n",
    "                                        datasets[i]['Id_Cliente'],\n",
    "                                        datasets[i]['Curso'],\n",
    "                                        datasets[i]['Asignatura'],\n",
    "                                        datasets[i]['Tipo Material Educativo'],\n",
    "                                        datasets[i]['Lengua'],\n",
    "                                        datasets[i]['Tipo Soporte Actual']))\n",
    "    \n",
    "    # create a column for non use, use exception throwing because data_2019 doesn't have the 'Grupo Editorial' column\n",
    "    try:\n",
    "        # create column name in the form non_use_YYYY\n",
    "        column_name = 'non_use_' + str(datasets[i]['Año natural'].unique()[0])\n",
    "        \n",
    "        # create binary column with 1 where Grupo Editorial = 90 (non-use)\n",
    "        datasets[i][column_name] = np.where(datasets[i]['Grupo Editorial'] == 90, 1, 0)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# merge all four dataframes into one on the record_id\n",
    "target_df = reduce(lambda x, y: pd.merge(x, y, how = 'outer', on = 'record_id'), datasets)\n",
    "\n",
    "# keep only the non_use columns and the record_id\n",
    "target_df = target_df[['record_id', 'non_use_2016', 'non_use_2017', 'non_use_2018']].copy()\n",
    "\n",
    "# create the target \n",
    "target_df['target_2017'] = np.where((target_df.non_use_2016 == 0) & (target_df.non_use_2017 == 1), 1, 0)\n",
    "target_df['target_2018'] = np.where((target_df.non_use_2017 == 0) & (target_df.non_use_2018 == 1), 1, 0)\n",
    "\n",
    "# add target to dataframes for 2016 and 2017\n",
    "datasets[1] = datasets[1].merge(target_df[['record_id', 'target_2017']], how = 'left', on = 'record_id')\n",
    "datasets[2] = datasets[2].merge(target_df[['record_id', 'target_2018']], how = 'left', on = 'record_id')\n",
    "\n",
    "# rename columns to allow concatenation on these columns\n",
    "datasets[0] = datasets[0].rename(columns = {'non_use_2016':'non_use'})\n",
    "datasets[1] = datasets[1].rename(columns = {'non_use_2017':'non_use', 'target_2017':'target'})\n",
    "datasets[2] = datasets[2].rename(columns = {'non_use_2018':'non_use', 'target_2018':'target'})\n",
    "\n",
    "# add column indicating if the record is a non_user in the previous year\n",
    "datasets[1] = datasets[1].merge(datasets[0][['record_id', 'non_use', 'Grupo Editorial']], \n",
    "                                how = 'left', \n",
    "                                on = 'record_id', \n",
    "                                suffixes = ('', '_previous'))\n",
    "\n",
    "datasets[2] = datasets[2].merge(datasets[1][['record_id', 'non_use', 'Grupo Editorial']], \n",
    "                                how = 'left', \n",
    "                                on = 'record_id', \n",
    "                                suffixes = ('', '_previous'))\n",
    "\n",
    "datasets[3] = datasets[3].merge(datasets[2][['record_id', 'non_use', 'Grupo Editorial']], \n",
    "                                how = 'left', \n",
    "                                on = 'record_id', \n",
    "                                suffixes = ('', '_previous'))\n",
    "\n",
    "# concatenate data into one dataframe\n",
    "data = pd.concat(datasets, sort = False, ignore_index = True)\n",
    "\n",
    "# rename columns\n",
    "data.rename(columns = {'Id_Cliente' : 'client_id', \n",
    "                       'Año natural' : 'year', \n",
    "                       'Curso' : 'course_code',\n",
    "                       'Asignatura' : 'subject_code',\n",
    "                       'Tipo Material Educativo' : 'material_type_code', \n",
    "                       'Grupo Editorial' : 'editorial_group', \n",
    "                       'Lengua' : 'language_code',\n",
    "                       'Tipo Soporte Actual' : 'media_support_code',\n",
    "                       'Variable1' : 'class_size',\n",
    "                       'Variable2' : 'monetary_value',\n",
    "                       'N_Asignatura' : 'subject_name',\n",
    "                       'Latitud' : 'latitude', \n",
    "                       'Longitud' : 'longitude', \n",
    "                       'Comunidad Autónoma' : 'state', \n",
    "                       'Id_Asociación' : 'association_id',\n",
    "                       'Id_Subasociación' : 'subassociation_id', \n",
    "                       'Titularidad' : 'school_type', \n",
    "                       'N_Curso' : 'course_name', \n",
    "                       'N_Lengua' : 'language_name', \n",
    "                       'N_TME' : 'material_type_name',\n",
    "                       'N_TS' : 'media_support_name',\n",
    "                       'Grupo Editorial_previous' : 'editorial_group_previous'},\n",
    "            inplace = True)\n",
    "\n",
    "# delete unnecessary variables to free up RAM\n",
    "del asignaturas, clientes, cursos, lengua, tme, ts, data_2016, data_2017, data_2018, data_2019, datasets, target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
